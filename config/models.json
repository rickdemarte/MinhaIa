{
  "aws": {
    "models": {
      "transcribe": {
        "model": "transcribe",
        "max_tokens": 1,
        "bucket_name": "ribeiro",
        "description": "Modelo de transcrição de áudio da AWS",
        "is_transcribe": true
      }
    }
  },
  "whisper": {
    "models": {
      "default": {
        "model": "whisper-1",
        "max_tokens": 20000,
        "description": "Modelo de transcrição de áudio da OpenAI",
        "is_transcribe": true
      },
      "smart": {
        "model": "gpt-4o-transcribe",
        "max_tokens": 20000,
        "description": "Modelo de transcrição de áudio da OpenAI",
        "is_transcribe": true
      },
      "fast": {
        "model": "gpt-4o-mini-transcribe",
        "max_tokens": 2000,
        "description": "Modelo de transcrição de áudio da OpenAI",
        "is_transcribe": true
      }
    }
  },
  "openai": {
    "models": {
      "fast": {
        "model": "gpt-4o-mini",
        "max_tokens": 4096,
        "description": "rápido e econômico"
      },
      "cheap": {
        "model": "gpt-4o-mini",
        "max_tokens": 4096,
        "description": "rápido e econômico"
      },
      "smart": {
        "model": "gpt-4o",
        "max_tokens": 16384,
        "description": "equilibrado"
      },
      "smartest": {
        "model": "o3-mini",
        "max_tokens": 100000,
        "description": "raciocínio profundo",
        "is_o_model": true
      },
      "absurdo": {
        "model": "o3",
        "max_tokens": 100000,
        "description": "máximo poder",
        "is_o_model": true
      },
      "default": {
        "model": "chatgpt-4o-latest",
        "max_tokens": 8192,
        "description": "padrão"
      }
    }
  },
  "assistant": {
    "models": {
      "fast": {
        "model": "gpt-4.1-nano",
        "max_tokens": 32768,
        "description": "rápido e econômico"
      },
      "cheap": {
        "model": "gpt-4o-mini",
        "max_tokens": 8192,
        "description": "rápido e econômico"
      },
      "smart": {
        "model": "gpt-4.1",
        "max_tokens": 32768,
        "description": "equilibrado"
      },
      "smartest": {
        "model": "o3-mini",
        "max_tokens": 100000,
        "description": "Reasoning, mas nem tanto",
        "is_o_model": true
      },
      "default": {
        "model": "gpt-4.1",
        "max_tokens": 32768,
        "description": "Resposta padrão, mas não é de graça"
      }
    }
  },
  "deepseek": {
    "models": {
      "fast": {
        "model": "deepseek-chat",
        "max_tokens":4096,
        "description":"Modelo Chat simples 4K tokens"
      },
      "cheap": {
        "model": "deepseek-chat",
        "max_tokens":4096,
        "description":"Modelo Chat simples 4K tokens"
      },
      "smart": {
        "model": "deepseek-reasoner",
        "max_tokens":32000,
        "description":"Modelo Reasoner 32K tokens"
      },
      "smartest": {
        "model": "deepseek-reasoner",
        "max_tokens":64000,
        "description":"Modelo Chat Reasoner 64K tokens"
      },
      "default": {
        "model": "deepseek-chat",
        "max_tokens":8192,
        "description":"Modelo Chat simples 8K tokens"
      }
    }
  },
  "claude": {
    "models": {
      "fast": {
        "model": "claude-3-5-haiku-20241022",
        "max_tokens": 8192,
        "description": "rápido e econômico"
      },
      "cheap": {
        "model": "claude-3-5-haiku-20241022",
        "max_tokens": 8192,
        "description": "rápido e econômico"
      },
      "smart": {
        "model": "claude-sonnet-4-20250514",
        "max_tokens": 8192,
        "description": "equilibrado"
      },
      "smartest": {
        "model": "claude-opus-4-20250514",
        "max_tokens": 8192,
        "description": "mais inteligente"
      },
      "default": {
        "model": "claude-3-7-sonnet-20250219",
        "max_tokens": 64000,
        "description": "padrão"
      }
    }
  },
  "qwen":{
    "models": {
      "fast": {
        "model": "qwen-turbo-latest",
        "max_tokens": 8192,
        "description": "modelo rápido e econômico para tarefas simples"
      },
      "cheap": {
        "model": "qwen-turbo-latest",
        "max_tokens": 8192,
        "description": "modelo rápido e econômico para tarefas simples"
      },
      "smart": {
        "model": "qwen-max",
        "max_tokens": 8192,
        "description": "maior capacidade de raciocínio, ideal para tarefas complexas"
      },
      "smartest": {
        "model": "qvq-max",
        "max_tokens": 8192,
        "description": "Modelo Reasoner 8K tokens"
      },
      "default": {
        "model": "qwen-plus",
        "max_tokens": 8192,
        "description": "equilíbrio entre custo e desempenho para tarefas mais complexas"
      }
    }
  },
  "grok": {
    "models": {
      "fast": {
        "model": "grok-3-fast",
        "max_tokens": 131072,
        "description": "Modelo otimizado para velocidade"
      },
      "cheap": {
          "model": "grok-3-mini",
          "max_tokens": 131072,
          "description": "Modelo mais econômico para tarefas leves"
      },
      "smart": {
        "model": "grok-3",
        "max_tokens": 131072,
        "description": "Modelo padrão para tarefas empresariais"
      },
      "smartest": {
        "model": "grok-3",
        "max_tokens": 131072,
        "description": "Melhor modelo não-raciocinante"
      },
      "absurdo": {
        "model": "grok-4-0709",
        "max_tokens": 256000,
        "description": "Melhor modelo raciocinante com alta capacidade"
      }
    }
  },
  "groq": {
    "models": {
      "fast": {
        "model": "llama-3.1-8b-instant",
        "max_tokens": 131072,
        "description": "Modelo Llama 3.1 8B instantâneo"
      },
      "cheap":{
        "model": "meta-llama/llama-4-maverick-17b-128e-instruct",
        "max_tokens": 8192,
        "description": "Versão “maverick”: mais qualidade que o Scout, ainda barata"
      },
      "smart": {
        "model": "qwen/qwen3-32b",
        "max_tokens": 40960,
        "description": "Modelo Qwen 3 32B com alta capacidade de raciocínio"
      },
      "smartest": {
        "model": "deepseek-r1-distill-llama-70b",
        "max_tokens": 131072,
        "description": "Modelo DeepSeek R1 destilado em Llama 70B"
      },
      "absurdo": {
        "model": "openai/gpt-oss-120b",
        "max_tokens": 32766,
        "description": "Modelo da OpenAI GPT-OSS 120B"
      },
      "default": {
        "model": "openai/gpt-oss-120b",
        "max_tokens": 8192,
        "description": "Modelo da OpenAI GPT-OSS 120B"
      }
    }
  },
  "gemini": {
    "models": {
      "fast": {
        "model": "models/gemini-2.5-flash-lite",
        "max_tokens": 8192,
        "description": "Resposta rápida e econômica"
      },
      "cheap": {
        "model": "models/gemini-2.0-flash-lite",
        "max_tokens": 8192,
        "description": "Resposta rápida e econômica"
      },
      "smart": {
        "model": "models/gemini-1.5-pro-latest",
        "max_tokens": 32768,
        "description": "Equilíbrio entre custo e desempenho"
      },
      "smartest":{
        "model": "models/gemini-2.5-flash-latest",
        "max_tokens": 32768,
        "description": "Mais inteligente"
      },
      "absurdo": {
        "model": "models/gemini-2.5-pro-latest",
        "max_tokens": 32768,
        "description": "Melhor modelo não-raciocinante"
      },
      "default": {
        "model": "models/gemini-2.5-flash",
        "max_tokens": 32768,
        "description": "padrão"
      }
    }
  },
  "dryrun": {
    "models": {
      "default": {
        "model": "Nenhum",
        "max_tokens": 1,
        "description": "Modelo apenas para registro para não mecher no código"
      }
    }
  }
}